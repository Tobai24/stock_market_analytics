{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da5ac074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import yfinance as yf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5f1a9",
   "metadata": {},
   "source": [
    "### Question 1: [Index] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia's [S&P 500 companies page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies), download the data including the year each company was added to the index.\n",
    "\n",
    "Hint: you can use [pandas.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) to scrape the data into a DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame with company tickers, names, and the year they were added.\n",
    "2. Extract the year from the addition date and calculate the number of stocks added each year.\n",
    "3. Which year had the highest number of additions (1957 doesn't count, as it was the year when the S&P 500 index was founded)? Write down this year as your answer (the most recent one, if you have several records).\n",
    "\n",
    "*Context*: \n",
    "> \"Following the announcement, all four new entrants saw their stock prices rise in extended trading on Friday\" - recent examples of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying)).\n",
    "\n",
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7788ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de4252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fe1f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol             Security             GICS Sector  \\\n",
       "0    MMM                   3M             Industrials   \n",
       "1    AOS          A. O. Smith             Industrials   \n",
       "2    ABT  Abbott Laboratories             Health Care   \n",
       "3   ABBV               AbbVie             Health Care   \n",
       "4    ACN            Accenture  Information Technology   \n",
       "\n",
       "                GICS Sub-Industry    Headquarters Location  Date added  \\\n",
       "0        Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
       "1               Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
       "2           Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
       "3                   Biotechnology  North Chicago, Illinois  2012-12-31   \n",
       "4  IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
       "\n",
       "       CIK      Founded  \n",
       "0    66740         1902  \n",
       "1    91142         1916  \n",
       "2     1800         1888  \n",
       "3  1551152  2013 (1888)  \n",
       "4  1467373         1989  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180ce29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Symbol', 'Security', 'GICS Sector', 'GICS Sub-Industry',\n",
       "       'Headquarters Location', 'Date added', 'CIK', 'Founded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee759da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date first added'] = pd.to_datetime(df['Date added'], errors='coerce')\n",
    "df['Year added'] = df['Date first added'].dt.year\n",
    "year_counts = df['Year added'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be5aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_counts = year_counts[year_counts.index != 1957]\n",
    "most_additions_year = year_counts[year_counts == year_counts.max()].index[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99aa2f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_additions_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75724c",
   "metadata": {},
   "source": [
    "_How many current S&P 500 stocks have been in the index for more than 20 years?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad760d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of S&P 500 companies with >20 years in index: 219\n"
     ]
    }
   ],
   "source": [
    "current_year = datetime.datetime.now().year\n",
    "df['Years in index'] = current_year - df['Year added']\n",
    "long_tenure_count = (df['Years in index'] > 20).sum()\n",
    "\n",
    "print(\"Number of S&P 500 companies with >20 years in index:\", long_tenure_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801cac6",
   "metadata": {},
   "source": [
    "### Question 2. [Macro] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD) performance (1 January-1 May 2025) of major stock market indexes for the following countries:\n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China - Shanghai Composite (000001.SS)\n",
    "* Hong Kong - HANG SENG INDEX (^HSI)\t\n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date='2025-01-01' and end_date='2025-05-01' when downloading daily data in yfinance\n",
    "\n",
    "Context: \n",
    "> [Global Valuations: Who's Cheap, Who's Not?](https://simplywall.st/article/beyond-the-us-global-markets-after-yet-another-tariff-update) article suggests \"Other regions may be growing faster than the US and you need to diversify.\"\n",
    "\n",
    "Reference: Yahoo Finance World Indices - https://finance.yahoo.com/world-indices/\n",
    "\n",
    "*Additional*: How many of these indexes have better returns than the S&P 500 over 3, 5, and 10 year periods? Do you see the same trend?\n",
    "Note: For simplicity, ignore currency conversion effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "055584c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tickers = {\n",
    "    \"United States - S&P 500\": \"^GSPC\",\n",
    "    \"China - Shanghai Composite\": \"000001.SS\",\n",
    "    \"Hong Kong - Hang Seng\": \"^HSI\",\n",
    "    \"Australia - ASX 200\": \"^AXJO\",\n",
    "    \"India - Nifty 50\": \"^NSEI\",\n",
    "    \"Canada - TSX\": \"^GSPTSE\",\n",
    "    \"Germany - DAX\": \"^GDAXI\",\n",
    "    \"UK - FTSE 100\": \"^FTSE\",\n",
    "    \"Japan - Nikkei 225\": \"^N225\",\n",
    "    \"Mexico - IPC\": \"^MXX\",\n",
    "    \"Brazil - Ibovespa\": \"^BVSP\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d579e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze returns\n",
    "results = {index: {} for index in index_tickers.keys()}\n",
    "\n",
    "periods = {\n",
    "        'This year': ('2025-01-01', '2025-05-01'),\n",
    "        '3 Year': ('2022-05-01', '2025-05-01'),\n",
    "        '5 Year': ('2020-05-01', '2025-05-01'),\n",
    "        '10 Year': ('2015-05-01', '2025-05-01')\n",
    "    }\n",
    "\n",
    "for years, (start_date, end_date) in periods.items():\n",
    "    for names, symbols in index_tickers.items():\n",
    "        ticker = yf.Ticker(symbols)\n",
    "        data = ticker.history(start=start_date, end=end_date)\n",
    "        \n",
    "        if not data.empty:\n",
    "            start_price = data.iloc[0]['Close']\n",
    "            end_price = data.iloc[-1]['Close']\n",
    "            ytd_return = ((end_price - start_price) / start_price) * 100\n",
    "            results[names][years] = ytd_return\n",
    "        else:\n",
    "            print(f\"{names:<30}: No data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f92b6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period                      This year     3 Year      5 Year     10 Year\n",
      "Index                                                                   \n",
      "United States - S&P 500     -5.103301  34.020480   96.737219  164.150565\n",
      "China - Shanghai Composite   0.504817   6.886816   13.928827  -26.814921\n",
      "Hong Kong - Hang Seng       12.720018   4.821935   -6.328463  -21.349909\n",
      "Australia - ASX 200         -0.914500  10.605692   54.905743   39.759912\n",
      "India - Nifty 50             2.490424  42.562875  161.841063  192.058866\n",
      "Canada - TSX                -0.226126  20.053451   69.912379   61.942786\n",
      "Germany - DAX               12.346378  61.395129  114.936570   93.608190\n",
      "UK - FTSE 100                2.842590  12.347091   47.401576   21.598918\n",
      "Japan - Nikkei 225          -8.297931  34.404756   83.723618   84.548741\n",
      "Mexico - IPC                13.049444   8.425565   54.684126   24.361595\n",
      "Brazil - Ibovespa           12.438710  26.658164   71.239667  135.497088\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "returns_df = pd.DataFrame(results).T\n",
    "returns_df.columns.name = \"Period\"\n",
    "returns_df.index.name = \"Index\"\n",
    "print(returns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9933ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This year: 9 indices beat the S&P 500 (-5.10%)\n",
      "3 Year: 3 indices beat the S&P 500 (34.02%)\n",
      "5 Year: 2 indices beat the S&P 500 (96.74%)\n",
      "10 Year: 1 indices beat the S&P 500 (164.15%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for period in periods.keys():\n",
    "    period_results = {index: returns_df.loc[index, period] for index in returns_df.index}\n",
    "\n",
    "    sp500_period = period_results.get('United States - S&P 500', np.nan)\n",
    "\n",
    "    if not np.isnan(sp500_period):\n",
    "        better_than_sp500 = sum(\n",
    "            1 for name, ret in period_results.items()\n",
    "            if not np.isnan(ret) and ret > sp500_period and name != 'United States - S&P 500'\n",
    "        )\n",
    "        print(f\"{period}: {better_than_sp500} indices beat the S&P 500 ({sp500_period:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"{period}: S&P 500 return not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848caaa",
   "metadata": {},
   "source": [
    "### Question 3. [Index] S&P 500 Market Corrections Analysis\n",
    "\n",
    "\n",
    "**Calculate the median duration (in days) of significant market corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps:\n",
    "1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "2. Identify all-time high points (where price exceeds all previous prices)\n",
    "3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "4. Calculate drawdown percentages: (high - low) / high Ã— 100\n",
    "5. Filter for corrections with at least 5% drawdown\n",
    "6. Calculate the duration in days for each correction period\n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "*Context:* \n",
    "> * Investors often wonder about the typical length of market corrections when deciding \"when to buy the dip\" ([Reddit discussion](https://www.reddit.com/r/investing/comments/1jrqnte/when_are_you_buying_the_dip/?rdt=64135)).\n",
    "\n",
    "> * [A Wealth of Common Sense - How Often Should You Expect a Stock Market Correction?](https://awealthofcommonsense.com/2022/01/how-often-should-you-expect-a-stock-market-correction/)\n",
    "\n",
    "*Hint (use this data to compare with your results)*: Here is the list of top 10 largest corrections by drawdown:\n",
    "* 2007-10-09 to 2009-03-09: 56.8% drawdown over 517 days\n",
    "* 2000-03-24 to 2002-10-09: 49.1% drawdown over 929 days\n",
    "* 1973-01-11 to 1974-10-03: 48.2% drawdown over 630 days\n",
    "* 1968-11-29 to 1970-05-26: 36.1% drawdown over 543 days\n",
    "* 2020-02-19 to 2020-03-23: 33.9% drawdown over 33 days\n",
    "* 1987-08-25 to 1987-12-04: 33.5% drawdown over 101 days\n",
    "* 1961-12-12 to 1962-06-26: 28.0% drawdown over 196 days\n",
    "* 1980-11-28 to 1982-08-12: 27.1% drawdown over 622 days\n",
    "* 2022-01-03 to 2022-10-12: 25.4% drawdown over 282 days\n",
    "* 1966-02-09 to 1966-10-07: 22.2% drawdown over 240 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "65f0b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "sp_500_hist = yf.Ticker(\"^GSPC\").history(start=\"1950-01-01\", end=\"2025-01-01\")\n",
    "# step 2\n",
    "sp_500_hist['All_Time_High'] = sp_500_hist['Close'].cummax()\n",
    "sp_500_hist[\"is_all_time_high\"] = sp_500_hist[\"All_Time_High\"] == sp_500_hist[\"Close\"] \n",
    "# step 3\n",
    "ath_dates = sp_500_hist[sp_500_hist[\"is_all_time_high\"]].index.to_list()\n",
    "\n",
    "corrections = []\n",
    "\n",
    "for i in range(len(ath_dates) - 1):\n",
    "    start = ath_dates[i]\n",
    "    next_ath = ath_dates[i + 1]\n",
    "    window = sp_500_hist.loc[start:next_ath]\n",
    "\n",
    "    price_series = window['Close'][1:]\n",
    "    if price_series.empty:\n",
    "        continue\n",
    "    \n",
    "    min_price = price_series.min()\n",
    "    min_date = price_series.idxmin()\n",
    "\n",
    "    # step 4: Calculate drawdown percentage\n",
    "    drawdown_pct = (sp_500_hist.loc[start, 'Close'] - min_price) / sp_500_hist.loc[start, 'Close'] * 100\n",
    "    \n",
    "    # step 5\n",
    "    if drawdown_pct > 5:\n",
    "        # step 6\n",
    "        duration = (min_date - start).days\n",
    "        corrections.append({\n",
    "            'start_date': start,\n",
    "            'end_date': min_date,\n",
    "            'min_date': min_date,\n",
    "            'drawdown_pct': drawdown_pct,\n",
    "            'duration_days': duration\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b0cf9a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>min_date</th>\n",
       "      <th>drawdown_pct</th>\n",
       "      <th>duration_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-06-12 00:00:00-04:00</td>\n",
       "      <td>1950-07-17 00:00:00-04:00</td>\n",
       "      <td>1950-07-17 00:00:00-04:00</td>\n",
       "      <td>14.020615</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-11-24 00:00:00-05:00</td>\n",
       "      <td>1950-12-04 00:00:00-05:00</td>\n",
       "      <td>1950-12-04 00:00:00-05:00</td>\n",
       "      <td>6.496062</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1951-05-03 00:00:00-04:00</td>\n",
       "      <td>1951-06-29 00:00:00-04:00</td>\n",
       "      <td>1951-06-29 00:00:00-04:00</td>\n",
       "      <td>8.110480</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951-10-15 00:00:00-05:00</td>\n",
       "      <td>1951-11-23 00:00:00-05:00</td>\n",
       "      <td>1951-11-23 00:00:00-05:00</td>\n",
       "      <td>6.079668</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952-01-22 00:00:00-05:00</td>\n",
       "      <td>1952-02-20 00:00:00-05:00</td>\n",
       "      <td>1952-02-20 00:00:00-05:00</td>\n",
       "      <td>6.366584</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 start_date                  end_date  \\\n",
       "0 1950-06-12 00:00:00-04:00 1950-07-17 00:00:00-04:00   \n",
       "1 1950-11-24 00:00:00-05:00 1950-12-04 00:00:00-05:00   \n",
       "2 1951-05-03 00:00:00-04:00 1951-06-29 00:00:00-04:00   \n",
       "3 1951-10-15 00:00:00-05:00 1951-11-23 00:00:00-05:00   \n",
       "4 1952-01-22 00:00:00-05:00 1952-02-20 00:00:00-05:00   \n",
       "\n",
       "                   min_date  drawdown_pct  duration_days  \n",
       "0 1950-07-17 00:00:00-04:00     14.020615             35  \n",
       "1 1950-12-04 00:00:00-05:00      6.496062             10  \n",
       "2 1951-06-29 00:00:00-04:00      8.110480             57  \n",
       "3 1951-11-23 00:00:00-05:00      6.079668             39  \n",
       "4 1952-02-20 00:00:00-05:00      6.366584             29  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "corrections_df = pd.DataFrame(corrections)\n",
    "corrections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1d94f5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>min_date</th>\n",
       "      <th>drawdown_pct</th>\n",
       "      <th>duration_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2007-10-09 00:00:00-04:00</td>\n",
       "      <td>2009-03-09 00:00:00-04:00</td>\n",
       "      <td>2009-03-09 00:00:00-04:00</td>\n",
       "      <td>56.775388</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2000-03-24 00:00:00-05:00</td>\n",
       "      <td>2002-10-09 00:00:00-04:00</td>\n",
       "      <td>2002-10-09 00:00:00-04:00</td>\n",
       "      <td>49.146948</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1973-01-11 00:00:00-05:00</td>\n",
       "      <td>1974-10-03 00:00:00-04:00</td>\n",
       "      <td>1974-10-03 00:00:00-04:00</td>\n",
       "      <td>48.203593</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1968-11-29 00:00:00-05:00</td>\n",
       "      <td>1970-05-26 00:00:00-04:00</td>\n",
       "      <td>1970-05-26 00:00:00-04:00</td>\n",
       "      <td>36.061641</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>2020-03-23 00:00:00-04:00</td>\n",
       "      <td>2020-03-23 00:00:00-04:00</td>\n",
       "      <td>33.924960</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1987-08-25 00:00:00-04:00</td>\n",
       "      <td>1987-12-04 00:00:00-05:00</td>\n",
       "      <td>1987-12-04 00:00:00-05:00</td>\n",
       "      <td>33.509515</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1961-12-12 00:00:00-05:00</td>\n",
       "      <td>1962-06-26 00:00:00-04:00</td>\n",
       "      <td>1962-06-26 00:00:00-04:00</td>\n",
       "      <td>27.973568</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1980-11-28 00:00:00-05:00</td>\n",
       "      <td>1982-08-12 00:00:00-04:00</td>\n",
       "      <td>1982-08-12 00:00:00-04:00</td>\n",
       "      <td>27.113582</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2022-01-03 00:00:00-05:00</td>\n",
       "      <td>2022-10-12 00:00:00-04:00</td>\n",
       "      <td>2022-10-12 00:00:00-04:00</td>\n",
       "      <td>25.425097</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1966-02-09 00:00:00-05:00</td>\n",
       "      <td>1966-10-07 00:00:00-04:00</td>\n",
       "      <td>1966-10-07 00:00:00-04:00</td>\n",
       "      <td>22.177335</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  start_date                  end_date  \\\n",
       "56 2007-10-09 00:00:00-04:00 2009-03-09 00:00:00-04:00   \n",
       "54 2000-03-24 00:00:00-05:00 2002-10-09 00:00:00-04:00   \n",
       "24 1973-01-11 00:00:00-05:00 1974-10-03 00:00:00-04:00   \n",
       "22 1968-11-29 00:00:00-05:00 1970-05-26 00:00:00-04:00   \n",
       "65 2020-02-19 00:00:00-05:00 2020-03-23 00:00:00-04:00   \n",
       "35 1987-08-25 00:00:00-04:00 1987-12-04 00:00:00-05:00   \n",
       "15 1961-12-12 00:00:00-05:00 1962-06-26 00:00:00-04:00   \n",
       "27 1980-11-28 00:00:00-05:00 1982-08-12 00:00:00-04:00   \n",
       "68 2022-01-03 00:00:00-05:00 2022-10-12 00:00:00-04:00   \n",
       "18 1966-02-09 00:00:00-05:00 1966-10-07 00:00:00-04:00   \n",
       "\n",
       "                    min_date  drawdown_pct  duration_days  \n",
       "56 2009-03-09 00:00:00-04:00     56.775388            517  \n",
       "54 2002-10-09 00:00:00-04:00     49.146948            928  \n",
       "24 1974-10-03 00:00:00-04:00     48.203593            629  \n",
       "22 1970-05-26 00:00:00-04:00     36.061641            542  \n",
       "65 2020-03-23 00:00:00-04:00     33.924960             32  \n",
       "35 1987-12-04 00:00:00-05:00     33.509515            101  \n",
       "15 1962-06-26 00:00:00-04:00     27.973568            195  \n",
       "27 1982-08-12 00:00:00-04:00     27.113582            621  \n",
       "68 2022-10-12 00:00:00-04:00     25.425097            281  \n",
       "18 1966-10-07 00:00:00-04:00     22.177335            239  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_corrections = corrections_df.sort_values(by=\"drawdown_pct\", ascending=False).head(10)\n",
    "top_10_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ccf35f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction Duration Percentiles (in days):\n",
      "0.25    22.5\n",
      "0.50    40.0\n",
      "0.75    90.0\n",
      "Name: duration_days, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Show 25th, 50th (median), and 75th percentiles for correction durations\n",
    "percentiles = corrections_df['duration_days'].quantile([0.25, 0.5, 0.75])\n",
    "print(\"Correction Duration Percentiles (in days):\")\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfd819",
   "metadata": {},
   "source": [
    "### Question 4.  [Stocks] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following positive earnings surprises days.**\n",
    "\n",
    "Steps:\n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv)) containing earnings dates, EPS estimates, and actual EPS. Make sure you are using the correct delimiter to read the data, such as in this command ```python pandas.read_csv(\"ha1_Amazon.csv\", delimiter=';') ```\n",
    "2. Download complete historical price data using yfinance\n",
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the *return* as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)\n",
    "4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\"). Both fields should be present in the file. You should obtain 36 data points for use in the descriptive analysis (median) later. \n",
    "5. Calculate 2-day percentage changes following positive earnings surprises. Show your answer in % (closest number to the 2nd digit): *return* * 100.0\n",
    "6. (Optional) Compare the median 2-day percentage change for positive surprises vs. all historical dates. Do you see the difference?\n",
    "\n",
    "Context: Earnings announcements, especially when they exceed analyst expectations, can significantly impact stock prices in the short term.\n",
    "\n",
    "Reference: Yahoo Finance earnings calendar - https://finance.yahoo.com/calendar/earnings?symbol=AMZN\n",
    "\n",
    "*Additional*: Is there a correlation between the magnitude of the earnings surprise and the stock price reaction? Does the market react differently to earnings surprises during bull vs. bear markets?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d675e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "amazon_csv = pd.read_csv(\"ha1_Amazon.csv\", sep=\";\")\n",
    "\n",
    "amazon_csv = amazon_csv.drop(index=116)\n",
    "\n",
    "amazon_csv['Earnings Date'] = amazon_csv['Earnings Date'].apply(lambda x: parser.parse(x).date())\n",
    "\n",
    "# Step 2: Download Amazon historical price data\n",
    "amazon_hist = yf.Ticker(\"AMZN\").history(start='1997-01-01', end=\"2025-01-01\")\n",
    "\n",
    "# Step 3\n",
    "amazon_hist[\"Close_Day1\"] = amazon_hist[\"Close\"]\n",
    "amazon_hist[\"Close_Day3\"] = amazon_hist[\"Close\"].shift(-2)\n",
    "amazon_hist[\"2_day_return\"] = (amazon_hist[\"Close_Day3\"] / amazon_hist[\"Close_Day1\"]) - 1\n",
    "\n",
    "# Step 4: Identify positive earnings surprises\n",
    "amazon_csv[\"Reported EPS\"] = pd.to_numeric(amazon_csv[\"Reported EPS\"], errors=\"coerce\")\n",
    "amazon_csv[\"EPS Estimate\"] = pd.to_numeric(amazon_csv[\"EPS Estimate\"], errors=\"coerce\")\n",
    "amazon_csv[\"Surprise (%)\"] = pd.to_numeric(amazon_csv[\"Surprise (%)\"], errors=\"coerce\")\n",
    "\n",
    "# Identify positive earnings surprises\n",
    "amazon_csv[\"Positive_Surprise\"] = (\n",
    "    (amazon_csv[\"Reported EPS\"] > amazon_csv[\"EPS Estimate\"]) |\n",
    "    (amazon_csv[\"Surprise (%)\"] > 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973bb39",
   "metadata": {},
   "source": [
    "### Question 5.  [Exploratory, optional] Brainstorm potential idea for your capstone project\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Describe the capstone project you would like to pursue, considering your aspirations, ML model predictions, and prior knowledge. Even if you are unsure at this stage, try to generate an idea you would like to explore-such as a specific asset class, country, industry vertical, or investment strategy. Be as specific as possible.\n",
    "\n",
    "*Example: I want to build a short-term prediction model for the US/India/Brazil stock markets, focusing on the largest stocks over a 30-day investment horizon. I plan to use RSI and MACD technical indicators and news coverage data to generate predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf89c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48776a0",
   "metadata": {},
   "source": [
    "### Question 6. [Exploratory, optional] Investigate new metrics\n",
    "\n",
    "**Free text answer**\n",
    "\n",
    "Using the data sources we have covered (or any others you find relevant), download and explore a few additional metrics or time series that could be valuable for your project. Briefly explain why you think each metric is useful. This does not need to be a comprehensive list-focus on demonstrating your ability to generate data requests based on your project description, identify and locate the necessary data, and explain how you would retrieve it using Python.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
